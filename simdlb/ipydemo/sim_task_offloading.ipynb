{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Task Offloading for Reactive LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from time import sleep, perf_counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Timer & Global Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# Constant definition\n",
    "# -----------------------------------------------------\n",
    "MIN_REL_LOAD_IMBALANCE = 0.05\n",
    "PERCENT_DIFF_TASKS_TO_OFFLOAD = 0.05\n",
    "THROUGHPUT = 0.25 # denotes 1 task/time unit\n",
    "LATENCY = 2\n",
    "DELAY = 2\n",
    "TIMESTEP_RATIO = 10 # e.g., 1 wallclock exetime = 10 timesteps\n",
    "NTASKS_OFFLOAD_AT_ONCE = 1\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Global status variables\n",
    "# -----------------------------------------------------\n",
    "global _time_step\n",
    "global _stop_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Task Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    \"\"\"\n",
    "    Class represent Task with its code entry, data, and childs (if yes).\n",
    "    - task_id: unique id of each task\n",
    "    - dur: duration or wallclock execution time of a task\n",
    "    - data: data size or arguments of a task\n",
    "    - childs: if yes\n",
    "    - start_time: to be executed\n",
    "    - end_time: to be termintated\n",
    "    - is_offloaded_task: a task which is offloaded or migrated from process i to process j\n",
    "    - off_time: offloaded time\n",
    "    - arr_time: arrived time\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task_id, dur, data):\n",
    "        self.task_id = task_id\n",
    "        self.dur = dur\n",
    "        self.data = data\n",
    "        # other info that can be configured while queueing\n",
    "        self.start_time = 0\n",
    "        self.end_time = 0\n",
    "        self.is_offloaded = False\n",
    "        self.off_time = 0\n",
    "        self.arr_time = 0\n",
    "        \n",
    "    def set_start_end_time(self, s_time, e_time):\n",
    "        self.start_time = s_time\n",
    "        self.end_time = e_time\n",
    "    \n",
    "    def set_offload_arrive_time(self, o_time, a_time):\n",
    "        self.is_offloaded_task = True\n",
    "        self.off_time = o_time\n",
    "        self.arr_time = a_time\n",
    "    \n",
    "    def get_dur(self):\n",
    "        return self.dur\n",
    "        \n",
    "    def get_end_time(self):\n",
    "        return self.end_time\n",
    "    \n",
    "    def task_info(self):\n",
    "        print('Task {}: dur({}), data({}), start_end_time({}-{}), is_offloaded({})'.format(self.task_id,\n",
    "                self.dur, self.data, self.start_time, self.end_time, self.is_offloaded))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Task Execution and Load Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# Util-functions\n",
    "# -----------------------------------------------------\n",
    "def load_task(queue, rank, timestep, mode, execu_task_arr,\n",
    "              local_taskexe_arr, remot_taskexe_arr):\n",
    "    cur_task = queue[rank].get()\n",
    "    dur = cur_task.get_dur()\n",
    "    s_time = timestep\n",
    "    e_time = s_time + dur\n",
    "    cur_task.set_start_end_time(s_time, e_time)\n",
    "    execu_task_arr[rank] = cur_task\n",
    "    # print('\\t P{}: Task {} starts running!'.format(rank, cur_task.task_id))\n",
    "    \n",
    "    # record the task execution for tracking\n",
    "    exe_interval = (s_time, dur)\n",
    "    if mode == 'local':\n",
    "        local_taskexe_arr[rank].append(exe_interval)\n",
    "    elif mode == 'remote':\n",
    "        remot_taskexe_arr[rank].append(exe_interval)\n",
    "\n",
    "def update_load(r, status_task_done, timestep, execu_task_arr,\n",
    "                local_load_arr, local_task_queue,\n",
    "                remot_load_arr, remot_task_queue,\n",
    "                local_taskexe_arr, remot_taskexe_arr):\n",
    "    # check the task which is being executed\n",
    "    if execu_task_arr[r] != None:\n",
    "        # check the task is finished or not\n",
    "        offloaded = execu_task_arr[r].is_offloaded\n",
    "        end_time = execu_task_arr[r].get_end_time()\n",
    "        if timestep == end_time:\n",
    "            # print('\\t P{}: Task {} is finishing...'.format(r, execu_task_arr[r].task_id))\n",
    "            execu_task_arr[r] = None\n",
    "        # else:\n",
    "            # print('\\t P{}: Task {} is running...'.format(r, execu_task_arr[r].task_id))\n",
    "            \n",
    "        # update the total load\n",
    "        if offloaded == True:\n",
    "            remot_load_arr[r] += 1\n",
    "        else:\n",
    "            local_load_arr[r] += 1\n",
    "                \n",
    "    # try to load task for executing when the array is empty\n",
    "    if execu_task_arr[r] == None:\n",
    "        # if remot_task_queue has some tasks | priority 1\n",
    "        if remot_task_queue[r].qsize() > 0:\n",
    "            load_task(remot_task_queue, r, timestep, 'remote', execu_task_arr, local_taskexe_arr, remot_taskexe_arr)\n",
    "        elif local_task_queue[r].qsize() > 0:\n",
    "            load_task(local_task_queue, r, timestep, 'local', execu_task_arr, local_taskexe_arr, remot_taskexe_arr)\n",
    "        else:\n",
    "            # assign the global stop condition\n",
    "            status_task_done[r] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# Summarize load information at the end\n",
    "# -----------------------------------------------------\n",
    "def load_info_statistic(local_load_arr, remot_load_arr):\n",
    "    print('------------------------------------------------')\n",
    "    print('Local load: {}'.format(local_load_arr))\n",
    "    print('Remot load: {}'.format(remot_load_arr))\n",
    "    \n",
    "    TOTAL_LOAD_ARR = np.add(local_load_arr, remot_load_arr)\n",
    "    print('Total load: {}'.format(TOTAL_LOAD_ARR))\n",
    "    print('Wallclock exetime: {}'.format(np.max(TOTAL_LOAD_ARR)))\n",
    "    print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Reactive Load Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# Offload & Receive tasks\n",
    "# -----------------------------------------------------\n",
    "def offload_tasks(src, des, ntasks, toffload, tarrive, loctask_queue, offtask_buff):\n",
    "    # dequeue tasks from src\n",
    "    offloaded_task = loctask_queue[src].get()\n",
    "    offloaded_task.is_offloaded = True\n",
    "    # set task info \n",
    "    migratabl_task = offloaded_task\n",
    "    migratabl_task.set_offload_arrive_time(toffload, tarrive)\n",
    "    # enqueue tasks to the offload-communication queue\n",
    "    offtask_buff[des].append(migratabl_task)\n",
    "    # print(\"[Offload] OFFLO_TASK_BUFFE[R{}], migratabl_task={}\".format(des, migratabl_task.task_id))\n",
    "\n",
    "def receive_tasks(offtask_buff, remottask_queue, num_ranks, timestamp):\n",
    "    for i in range(num_ranks):\n",
    "        if len(offtask_buff[i]) > 0:\n",
    "            for j in range(len(offtask_buff[i])):\n",
    "                tmp_task = offtask_buff[i][j]\n",
    "                tarrive = tmp_task.arr_time\n",
    "                if tarrive == timestamp:\n",
    "                    remote_task = offtask_buff[i].pop(j)\n",
    "                    # add remote task to the queue\n",
    "                    remottask_queue[i].put(remote_task)\n",
    "                    # print(\"[Receiv] REMOT_TASK_QUEUE[R{}], remote_task={}\".format(i, remote_task.task_id))\n",
    "                \n",
    "# -----------------------------------------------------\n",
    "# Balancing stuff\n",
    "# -----------------------------------------------------\n",
    "def balancing(timestep, local_task_queue, offload_task_buffer, num_ranks):\n",
    "    # check local queue status\n",
    "    QUEUE_SIZE_STATUS_ARR = np.zeros(num_ranks)\n",
    "    for r in range(num_ranks):\n",
    "        QUEUE_SIZE_STATUS_ARR[r] = local_task_queue[r].qsize()\n",
    "\n",
    "    # sort the queues by the current size status\n",
    "    sortLCQ = np.argsort(QUEUE_SIZE_STATUS_ARR)\n",
    "  \n",
    "    # show the status\n",
    "    str_rank_orders = '[ '\n",
    "    for i in range(len(sortLCQ)):\n",
    "        str_rank_orders += 'R' + str(sortLCQ[i]) + ' '\n",
    "    str_rank_orders += ']'\n",
    "  \n",
    "    str_load_orders = '[ '\n",
    "    for i in range(len(sortLCQ)):\n",
    "        idx = sortLCQ[i]\n",
    "        str_load_orders += str(local_task_queue[idx].qsize()) + ' '\n",
    "    str_load_orders += ']'\n",
    "\n",
    "    # calculate the imbalance ratio\n",
    "    lmax = QUEUE_SIZE_STATUS_ARR[sortLCQ[-1]]\n",
    "    lmin = QUEUE_SIZE_STATUS_ARR[sortLCQ[0]]\n",
    "    lavg = np.average(QUEUE_SIZE_STATUS_ARR)\n",
    "    rimb = 0.0\n",
    "    rimb_min_max = 0.0\n",
    "    if lavg != 0 and lmax != 0:\n",
    "        rimb = lmax/lavg - 1\n",
    "        rimb_min_max = (lmax - lmin) / lmax\n",
    "\n",
    "    # check the imbalance ratio\n",
    "    if rimb_min_max >= MIN_REL_LOAD_IMBALANCE:\n",
    "        # print(str_rank_orders + ' = ' + str_load_orders + ' | Imb. = ' + str(rimb))\n",
    "        # print('Ratio (max, min): {}'.format(rimb_min_max))\n",
    "\n",
    "        # calculate tasks to offload\n",
    "        OFFLOAD_PAIR_RANKS = []\n",
    "        for i in range(num_ranks):\n",
    "            src_ntasks = [-1,-1]\n",
    "            OFFLOAD_PAIR_RANKS.append(src_ntasks)\n",
    "\n",
    "        for i in range(int(num_ranks/2), num_ranks):\n",
    "            # check the number of tasks in src. rank\n",
    "            cur_qsize = local_task_queue[sortLCQ[i]].qsize()\n",
    "            if cur_qsize > 2:\n",
    "                OFFLOAD_PAIR_RANKS[i][0] = sortLCQ[i] # src. rank\n",
    "                OFFLOAD_PAIR_RANKS[i][1] = sortLCQ[num_ranks - i - 1] # des. rank\n",
    "                # print(\"[Debug] src_rank={}, des_rank={}...\".format(OFFLOAD_PAIR_RANKS[i][0], OFFLOAD_PAIR_RANKS[i][1]))\n",
    "\n",
    "        # offload tasks\n",
    "        for i in range(num_ranks):\n",
    "            if np.sum(OFFLOAD_PAIR_RANKS[i]) > 0:\n",
    "                src_rank = OFFLOAD_PAIR_RANKS[i][0]\n",
    "                des_rank = OFFLOAD_PAIR_RANKS[i][1]\n",
    "                ntasks2offload = NTASKS_OFFLOAD_AT_ONCE\n",
    "                t_offloa = timestep\n",
    "                t_arrive = timestep + int(ntasks2offload/THROUGHPUT)\n",
    "                # print(\"[Offload] R{} ---> R{}: {} task, send at t{}, recv at t{}\".format(src_rank, des_rank, ntasks2offload, t_offloa, t_arrive))\n",
    "                offload_tasks(src_rank, des_rank, ntasks2offload, t_offloa, t_arrive, local_task_queue, offload_task_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load Init & Simulator Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# Init offloading tracker array\n",
    "# -----------------------------------------------------\n",
    "def init_configuration(given_task_distribution, perf_slowdown_sets, timestep_ratio):\n",
    "    \n",
    "    # Total load recoder\n",
    "    GIVEN_TASK_ARR = given_task_distribution\n",
    "    PERFO_SLOWDOWN = perf_slowdown_sets\n",
    "    TIMESTEP_RATIO = timestep_ratio\n",
    "    num_ranks = len(GIVEN_TASK_ARR)\n",
    "    \n",
    "    LOCAL_LOAD_ARR = np.zeros((num_ranks,), dtype=int)\n",
    "    REMOT_LOAD_ARR = np.zeros((num_ranks,), dtype=int)\n",
    "    \n",
    "    # Offloading and task queues\n",
    "    EXECU_TASK_ARRAY = []\n",
    "    OFFLO_TASK_BUFFE = []\n",
    "    LOCAL_TASK_QUEUE = []\n",
    "    REMOT_TASK_QUEUE = []\n",
    "    # Array tracking task execution for visualization\n",
    "    LOCAL_TASKEXE_ARR = []\n",
    "    REMOT_TASKEXE_ARR = []\n",
    "\n",
    "    for i in range(len(GIVEN_TASK_ARR)):\n",
    "        OFFLO_TASK_BUFFE.append([])\n",
    "        LOCAL_TASK_QUEUE.append(Queue())\n",
    "        REMOT_TASK_QUEUE.append(Queue())\n",
    "\n",
    "        LOCAL_TASKEXE_ARR.append([])\n",
    "        REMOT_TASKEXE_ARR.append([])\n",
    "\n",
    "    for r in range(len(GIVEN_TASK_ARR)):\n",
    "        num_given_tasks = GIVEN_TASK_ARR[r]\n",
    "        r_to_tid = r * 10000 # to get a uniqe id for each task\n",
    "        for i in range(num_given_tasks):\n",
    "            tid = r_to_tid + i\n",
    "            dur = 1*TIMESTEP_RATIO*PERFO_SLOWDOWN[r]\n",
    "            data = 1 # such as 1MB\n",
    "            task = Task(tid, dur, data)\n",
    "            # put task to the queue\n",
    "            LOCAL_TASK_QUEUE[r].put(task)\n",
    "        \n",
    "    # Check the number of generated tasks on each process\n",
    "    # for r in range(len(GIVEN_TASK_ARR)):\n",
    "    #     print('Process {:2d}: {:3d} tasks, load/task ~{:5.1f}(time-unit)'.format(r,\n",
    "    #                     LOCAL_TASK_QUEUE[r].qsize(), 1*TIMESTEP_RATIO*PERFO_SLOWDOWN[r]))\n",
    "        \n",
    "    ret = [GIVEN_TASK_ARR,\n",
    "          LOCAL_LOAD_ARR, REMOT_LOAD_ARR,\n",
    "          EXECU_TASK_ARRAY, OFFLO_TASK_BUFFE,\n",
    "          LOCAL_TASK_QUEUE, REMOT_TASK_QUEUE,\n",
    "          LOCAL_TASKEXE_ARR, REMOT_TASKEXE_ARR]\n",
    "    return ret\n",
    "        \n",
    "# Test the function\n",
    "# tmp = init_configuration([5,5,5,5,5,5,5,5], [0.5,0.5,0.5,0.5,1.0,1.0,1.0,1.0], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "#### Visualize Task Execution without Load Balancing\n",
    "* $L_{i}$: denotes the total load of Process $i$\n",
    "* $w_{i}$: denotes the wallclock exetime of each task\n",
    "* With a given distribution of tasks, $T_{i}$ indicates the set of tasks belonging to Process $i$\n",
    "* The model would be: $$ L(i) = \\sum_{j \\in T_{i}} w_{j} $$\n",
    "-----------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_timestamp(total_load_arr):\n",
    "    gnt_arr = []\n",
    "    for r in range(len(total_load_arr)):\n",
    "        tmp_arr = []\n",
    "        for i in range(len(total_load_arr[r])):\n",
    "            load_vals = total_load_arr[r]\n",
    "            start = i * load_vals[i]\n",
    "            dur = load_vals[i]\n",
    "            exe_interval = (start, dur)\n",
    "            tmp_arr.append(exe_interval)\n",
    "        gnt_arr.append(tmp_arr)\n",
    "    return gnt_arr\n",
    "\n",
    "def visualize_load_no_lb(ntaskp0, ntaskp1, ntaskp2, ntaskp3, ntaskp4, ntaskp5, ntaskp6, ntaskp7,\n",
    "                         pslowp0, pslowp1, pslowp2, pslowp3, pslowp4, pslowp5, pslowp6, pslowp7):\n",
    "    task_arr = [ntaskp0, ntaskp1, ntaskp2, ntaskp3, ntaskp4, ntaskp5, ntaskp6, ntaskp7]\n",
    "    perfslowdown_arr = [pslowp0, pslowp1, pslowp2, pslowp3, pslowp4, pslowp5, pslowp6, pslowp7]\n",
    "    max_ntasks = np.max(task_arr)\n",
    "    num_processes = len(task_arr)\n",
    "    total_load_arr = []\n",
    "    for i in range(num_processes):\n",
    "        n_tasks = task_arr[i]\n",
    "        load_per_task = 1 * TIMESTEP_RATIO * perfslowdown_arr[i]\n",
    "        load_per_rank = [load_per_task] * n_tasks\n",
    "        total_load_arr.append(load_per_rank)\n",
    "        # print('P{}: {}'.format(i, load_per_rank))\n",
    "    \n",
    "    # plot the gannt chart\n",
    "    fig, gnt = plt.subplots()\n",
    "    \n",
    "    # set labels for x- and y-axis\n",
    "    gnt.set_xlabel('Time Progress')\n",
    "    gnt.set_ylabel('Processes')\n",
    "    \n",
    "    # set x- or y-limits\n",
    "    gnt.set_xlim(0, max_ntasks*TIMESTEP_RATIO*1.0+TIMESTEP_RATIO*2)\n",
    "    \n",
    "    # set ticks on y-axis for showing the process-names\n",
    "    ytick_values = [15]\n",
    "    ytick_labels = ['P0']\n",
    "    for i in range(1, num_processes):\n",
    "        ytick_values.append(ytick_values[i-1] + 10)\n",
    "        ytick_labels.append('P' + str(i))\n",
    "    gnt.set_yticks(ytick_values)\n",
    "    gnt.set_yticklabels(ytick_labels)\n",
    "    \n",
    "    # configure the graph attributes\n",
    "    # gnt.grid(True)\n",
    "    \n",
    "    # segment task timestamp\n",
    "    gnt_load_arr = segment_timestamp(total_load_arr)\n",
    "    print(gnt_load_arr)\n",
    "    \n",
    "    # declare bars in schedule\n",
    "    for r in range(num_processes):\n",
    "        gnt.broken_barh(gnt_load_arr[r], (10*r+10, 8), facecolors=('tab:green'), edgecolor='black')\n",
    "\n",
    "    # display the chart\n",
    "    plt.show()\n",
    "\n",
    "# check the function\n",
    "# visualize_load_no_lb(5, 5, 5, 5, 5, 5, 5, 5,\n",
    "#                      0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04233e757bd34ba39acb946b93c8e37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='# tasks P0', max=50, min=5, step=5), IntSlider(value=5, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exetask_withoutlb_demo = interactive(visualize_load_no_lb,\n",
    "                        ntaskp0=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P0'),\n",
    "                        ntaskp1=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P1'),\n",
    "                        ntaskp2=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P2'),\n",
    "                        ntaskp3=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P3'),\n",
    "                        ntaskp4=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P4'),\n",
    "                        ntaskp5=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P5'),\n",
    "                        ntaskp6=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P6'),\n",
    "                        ntaskp7=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P7'),\n",
    "                        pslowp0=widgets.FloatSlider(min=0.1, max=1.0, value=0.5, step=0.1, description='Perf-Slowdown P0'),\n",
    "                        pslowp1=widgets.FloatSlider(min=0.1, max=1.0, value=0.5, step=0.1, description='Perf-Slowdown P1'),\n",
    "                        pslowp2=widgets.FloatSlider(min=0.1, max=1.0, value=0.5, step=0.1, description='Perf-Slowdown P2'),\n",
    "                        pslowp3=widgets.FloatSlider(min=0.1, max=1.0, value=0.5, step=0.1, description='Perf-Slowdown P3'),\n",
    "                        pslowp4=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, description='Perf-Slowdown P4'),\n",
    "                        pslowp5=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, description='Perf-Slowdown P5'),\n",
    "                        pslowp6=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, description='Perf-Slowdown P6'),\n",
    "                        pslowp7=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, description='Perf-Slowdown P7'))\n",
    "display(exetask_withoutlb_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Reactive Load Balancing Simulation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# Main simulation engine\n",
    "# -----------------------------------------------------\n",
    "global _time_step\n",
    "global _stop_condition\n",
    "global _stat_all_tasks_done\n",
    "\n",
    "def simulation_engine(given_task_distribution, perf_slowdown_sets, timestep_ratio):\n",
    "    \n",
    "    # refresh the arrays\n",
    "    ret_arrays = init_configuration(given_task_distribution, perf_slowdown_sets, timestep_ratio)\n",
    "\n",
    "    GIVEN_TASK_ARR = ret_arrays[0]\n",
    "    LOCAL_LOAD_ARR = ret_arrays[1]\n",
    "    REMOT_LOAD_ARR = ret_arrays[2]\n",
    "    EXECU_TASK_ARRAY = ret_arrays[3]\n",
    "    OFFLO_TASK_BUFFE = ret_arrays[4]\n",
    "    LOCAL_TASK_QUEUE = ret_arrays[5]\n",
    "    REMOT_TASK_QUEUE = ret_arrays[6]\n",
    "    LOCAL_TASKEXE_ARR = ret_arrays[7]\n",
    "    REMOT_TASKEXE_ARR = ret_arrays[8]\n",
    "    \n",
    "    _num_ranks = len(GIVEN_TASK_ARR)\n",
    "    _time_step = 0\n",
    "    _stop_condition = False\n",
    "    \n",
    "    # load the 1st tast into the execution buffer\n",
    "    for r in range(_num_ranks):\n",
    "        first_task = LOCAL_TASK_QUEUE[r].get()\n",
    "        dur = first_task.dur\n",
    "        s_time = 0\n",
    "        e_time = s_time + dur\n",
    "        first_task.set_start_end_time(s_time, e_time)\n",
    "        EXECU_TASK_ARRAY.append(first_task)\n",
    "        # record the 1st task for tracking\n",
    "        exe_1st_task_interval = (s_time, dur)\n",
    "        LOCAL_TASKEXE_ARR[r].append(exe_1st_task_interval)\n",
    "\n",
    "    # set the stop condition flags on each process\n",
    "    _stat_all_tasks_done = []\n",
    "    for r in range(_num_ranks):\n",
    "        _stat_all_tasks_done.append(0)\n",
    "\n",
    "    # main loop\n",
    "    while _stop_condition != True:\n",
    "        # increase time clock\n",
    "        _time_step = _time_step + 1\n",
    "        # print('------------------------------------------------')\n",
    "        # print('_time_step {}:'.format(_time_step))\n",
    "\n",
    "        # check and recieve offload tasks\n",
    "        receive_tasks(OFFLO_TASK_BUFFE, REMOT_TASK_QUEUE, _num_ranks, _time_step)\n",
    "\n",
    "        # dynamic balancing\n",
    "        balancing(_time_step, LOCAL_TASK_QUEUE, OFFLO_TASK_BUFFE, _num_ranks)\n",
    "\n",
    "        # update load/proces as parallel processing\n",
    "        for r in range(_num_ranks):\n",
    "            # for process r at timestep t\n",
    "            update_load(r, _stat_all_tasks_done, _time_step, EXECU_TASK_ARRAY,\n",
    "                        LOCAL_LOAD_ARR, LOCAL_TASK_QUEUE,\n",
    "                        REMOT_LOAD_ARR, REMOT_TASK_QUEUE,\n",
    "                        LOCAL_TASKEXE_ARR, REMOT_TASKEXE_ARR)\n",
    "\n",
    "        # check the stop condition for the main loop\n",
    "        if sum(_stat_all_tasks_done) == _num_ranks:\n",
    "            _stop_condition = True\n",
    "            load_info_statistic(LOCAL_LOAD_ARR, REMOT_LOAD_ARR)\n",
    "    \n",
    "    return LOCAL_TASKEXE_ARR, REMOT_TASKEXE_ARR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Local load: [ 60  60  60  60 120 120 120 120]\n",
      "Remot load: [30 30 30 30 15 15 15 15]\n",
      "Total load: [ 90  90  90  90 135 135 135 135]\n",
      "Wallclock exetime: 135\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[(0, 15.0), (15, 15.0), (60, 15.0), (75, 15.0)],\n",
       "  [(0, 15.0), (15, 15.0), (60, 15.0), (75, 15.0)],\n",
       "  [(0, 15.0), (15, 15.0), (60, 15.0), (75, 15.0)],\n",
       "  [(0, 15.0), (15, 15.0), (60, 15.0), (75, 15.0)],\n",
       "  [(0, 30.0), (30, 30.0), (75, 30.0), (105, 30.0)],\n",
       "  [(0, 30.0), (30, 30.0), (75, 30.0), (105, 30.0)],\n",
       "  [(0, 30.0), (30, 30.0), (75, 30.0), (105, 30.0)],\n",
       "  [(0, 30.0), (30, 30.0), (75, 30.0), (105, 30.0)]],\n",
       " [[(30, 30.0)],\n",
       "  [(30, 30.0)],\n",
       "  [(30, 30.0)],\n",
       "  [(30, 30.0)],\n",
       "  [(60, 15.0)],\n",
       "  [(60, 15.0)],\n",
       "  [(60, 15.0)],\n",
       "  [(60, 15.0)]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the simulation engine\n",
    "simulation_engine([5,5,5,5,5,5,5,5], [0.5,0.5,0.5,0.5,1.0,1.0,1.0,1.0], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_load_react_lb(ntaskp0, ntaskp1, ntaskp2, ntaskp3, ntaskp4, ntaskp5, ntaskp6, ntaskp7,\n",
    "                         pslowp0, pslowp1, pslowp2, pslowp3, pslowp4, pslowp5, pslowp6, pslowp7,\n",
    "                         time_ratio, offload_throughput):\n",
    "    # prepare inputs\n",
    "    given_task_dist = [ntaskp0, ntaskp1, ntaskp2, ntaskp3, ntaskp4, ntaskp5, ntaskp6, ntaskp7]\n",
    "    perf_slowdown_dist = [pslowp0, pslowp1, pslowp2, pslowp3, pslowp4, pslowp5, pslowp6, pslowp7]\n",
    "    THROUGHPUT = offload_throughput\n",
    "    num_processes = len(given_task_dist)\n",
    "    \n",
    "    # run simulation\n",
    "    local_task_arr, remot_task_arr = simulation_engine(given_task_dist, perf_slowdown_dist, time_ratio)\n",
    "    total_load_arr = np.add(local_task_arr, remot_task_arr)\n",
    "    max_load = np.max(total_load_arr)\n",
    "    max_x = 100\n",
    "    if max_load >= 100:\n",
    "        max_x = max_load + 20\n",
    "    \n",
    "    # plot the gannt chart\n",
    "    fig, gnt = plt.subplots()\n",
    "    \n",
    "    # set labels for x- and y-axis\n",
    "    gnt.set_xlabel('Time Progress')\n",
    "    gnt.set_ylabel('Processes')\n",
    "    \n",
    "    # set x- or y-limits\n",
    "    gnt.set_xlim(0, max_x)\n",
    "    \n",
    "    # set ticks on y-axis for showing the process-names\n",
    "    ytick_values = [15]\n",
    "    ytick_labels = ['P0']\n",
    "    for i in range(1, num_processes):\n",
    "        ytick_values.append(ytick_values[i-1] + 10)\n",
    "        ytick_labels.append('P' + str(i))\n",
    "    gnt.set_yticks(ytick_values)\n",
    "    gnt.set_yticklabels(ytick_labels)\n",
    "    \n",
    "    # configure the graph attributes\n",
    "    # gnt.grid(True)\n",
    "    \n",
    "    # declare bars in schedule\n",
    "    for r in range(num_processes):\n",
    "        gnt.broken_barh(local_task_arr[r], (10*r+10, 8), facecolors=('tab:green'), edgecolor='black')\n",
    "    for r in range(num_processes):\n",
    "        gnt.broken_barh(remot_task_arr[r], (10*r+10, 8), facecolors=('tab:orange'), edgecolor='black')\n",
    "\n",
    "    # display the chart\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee29bfdcbfe44cf48c3ec981bd533674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='# tasks P0', max=50, min=5, step=5), IntSlider(value=5, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exetask_withlb_demo = interactive(visualize_load_react_lb,\n",
    "                        ntaskp0=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P0'),\n",
    "                        ntaskp1=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P1'),\n",
    "                        ntaskp2=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P2'),\n",
    "                        ntaskp3=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P3'),\n",
    "                        ntaskp4=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P4'),\n",
    "                        ntaskp5=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P5'),\n",
    "                        ntaskp6=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P6'),\n",
    "                        ntaskp7=widgets.IntSlider(min=5, max=50, value=5, step=5, description='# tasks P7'),\n",
    "                        pslowp0=widgets.FloatSlider(min=0.1, max=1.0, value=0.5, step=0.1, description='Perf-Slowdown P0'),\n",
    "                        pslowp1=widgets.FloatSlider(min=0.1, max=1.0, value=0.5, step=0.1, description='Perf-Slowdown P1'),\n",
    "                        pslowp2=widgets.FloatSlider(min=0.1, max=1.0, value=0.5, step=0.1, description='Perf-Slowdown P2'),\n",
    "                        pslowp3=widgets.FloatSlider(min=0.1, max=1.0, value=0.5, step=0.1, description='Perf-Slowdown P3'),\n",
    "                        pslowp4=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, description='Perf-Slowdown P4'),\n",
    "                        pslowp5=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, description='Perf-Slowdown P5'),\n",
    "                        pslowp6=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, description='Perf-Slowdown P6'),\n",
    "                        pslowp7=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, description='Perf-Slowdown P7'),\n",
    "                        time_ratio=widgets.IntSlider(min=5, max=100, value=10, step=5, description='Timestep Ratio'),\n",
    "                        offload_throughput=widgets.FloatSlider(min=0.05, max=100.0, value=0.5, step=0.05, description='Offload Throughput'))\n",
    "display(exetask_withlb_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
