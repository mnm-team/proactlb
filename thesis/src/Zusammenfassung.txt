Hochleistungsrechnen (HPC) spielt eine Schlüsselrolle in der Wissenschaft und Forschung und löst komplexe Berechnungsprobleme. HPC setzt auf das parallele Rechnen und nutzt parallele Rechencluster für komplexe Berechnungen. Daher müssen Berechnungsprobleme als taskbasierte Applikationen auf diesen Clustern dargestellt werden. Die Lastenverteilung ist jedoch oft eine Herausforderung für taskbasierte Applikationen, insbesondere im Umgang mit Ungleichgewichten aufgrund von Leistungsverlangsamungen. Diese dynamische Natur macht traditionelle Ansätze wie die Vorverteilung oder die statische Lastenverteilung weniger effektiv.

Ein nützlicher Ansatz für Leistungsverlangsamungen zur Laufzeit ist das ``Work-stealing'', bei dem ein inaktiver Prozess Aufgaben von anderen übernehmen kann. Dies beinhaltet die Migration von Aufgaben und Daten zwischen Knoten, jedoch kann die Kommunikationsüberlastung in parallelen Rechenclustern die Diebstahlvorgänge verzögern. Eine Verbesserung ist das ``Reactive-load-balancing'', das die Verlagerung von Aufgaben von einem langsamen Prozess zu einem schnelleren Prozess früher als das Stehlen vorschlägt. Dieser reaktive Ansatz hat Einschränkungen, wenn Entscheidungen zur Aufgabenverlagerung auf Spekulationen basieren. Darüber hinaus ist der Mangel an Lastinformation ebenfalls ein Grund, der diese Entscheidungen behindert.

Unsere Arbeit trägt ein Leistungsmodell bei, um die Grenzen des reaktiven Lastenausgleichs zu analysieren. Wir schlagen einen neuen proaktiven Ansatz vor, um die Leistung noch weiter zu steigern. Das Hauptkonzept dreht sich um die Echtzeit-Erfassung von Lastinformationen, die eine proaktivere Lastenausgleichsstrategie ermöglicht. Im Detail nutzen wir das Ausführungsschema taskbasierter Programmiermodelle, bei dem ein Thread innerhalb eines Prozesses der Aufgabencharakterisierung, der Online-Lastvorhersage und der proaktiven Verlagerung von Aufgaben basierend auf Vorhersageergebnissen gewidmet ist. Daher erhalten wir Lastvorhersagewissen anstelle von fehlendem Vorwissen während der Ausführung. Wir können genauere Schätzungen zur Anzahl der Aufgaben und potenziellen Prozessen für die Verlagerung von Aufgaben machen. In unserem Ansatz stellen wir zwei Ausgleichsmethoden vor: die Feedback-Aufgabenverlagerung und die auf maschinellem Lernen basierende Aufgabenverlagerung. Außerdem schlagen wir eine Erweiterung vor, die die Koordination von Aufgaben über mehrere Applikationen hinweg erleichtert.

Um die Wirksamkeit unseres Ansatzes zu bewerten, verwenden wir Simulationen und experimentelle Tests. Die Testfälle umfassen synthetische Mikrobenchmarks und eine realistische Applikation mit adaptiver Netzverfeinerung. Unsere Ergebnisse bestätigen Vorteile in Szenarien mit hohem Ungleichgewicht und zeigen eine Beschleunigung von etwa $3.5\times$ im Vergleich zum zufälligen Work-stealing und $1.7\times$ zum reaktiven Lastenausgleich. In einer umfassenderen Sichtweise eröffnet unser Ansatz ein neues Schema zur Koordination von Aufgaben über mehrere Applikationen hinweg, um nicht nur die Leistung und Ressourcennutzung einer einzelnen Applikation, sondern auch mehrerer zu verbessern.

% Kontext und Herausforderung
% Bei task-parallelen Applikationen ist dynamische Lastverteilung oder Lastbalancierung oft eine Herausforderung, die davon abhängt, wie die Aufgaben verteilt sind. Normalerweise werden die Repartitionierungsalgorithmen im Vorfeld eingesetzt, um eine gleichmäßige Belastung zu gewährleisten. Eine Verlangsamung der Systemleistung kann jedoch zu einem falschen Kostenmodell für die Vorab-Partitionierung und damit zu einem neuen Ungleichgewicht zur Laufzeit führen.\\

% Aktuelle Richtungen und Grenzen
% In Bezug auf die dynamischen Lastverteilung wird in der Praxis häufig der Ansatz des Work-Stealing verfolgt. Tasks oder Works werden von überlasteten Prozessen übernommen, wenn die Queue der unterlasteten Prozesse leer ist. Work-Stealing ist praktisch und wird in fast allen Shared-Memory-Systemen eingesetzt. Bei verteiltem Memory können hohe Ungleichgewichte und Kommunikationsverzögerungen dazu führen, dass Work-Stealing zu spät erfolgt. Anstatt zu stehlen ist ein verbesserter Ansatz der reaktive Lastverteilung, bei dem wir versuchen, Tasks von einem langsamen Prozess in einen schnellen Prozess zu verschieben. Wir zeigen jedoch, dass auch diese Lösung zu spät kommen kann und begrenzt ist, wenn reaktive Lastverteilungsentscheidungen falsch getroffen werden. Der Grund dafür ist, dass die Migration von Tasks mit einem gewissen Overhead verbunden ist. Außerdem mangelt es konventionellen dynamischen Ansätzen an Load-Informationen, um eine bessere Lastverteilungsentscheidung zur Laufzeit treffen zu können. Zum Beispiel, wie viele Tasks auf einmal migriert werden sollen und welcher Prozess ein potentielles Opfer für die Lastverteilung ist.\\

% Meine Lösung
% In dieser Arbeit schlagen wir ein Performancesmodell vor, um die Effizienzgrenze von Work-Stealing und reaktivem Lastausgleich zu analysieren und abzuschätzen. Danach motivieren wir einen neuen proaktiven Ansatz zur Verbesserung des Load-Bilanzierung. Im Mittelpunkt dieses Ansatzes steht die Idee, einen speziellen Thread als Assistenten für andere Ausführungsthreads zur Verfügung zu stellen, um die Last proaktiv auszugleichen. Dieses Thema befasst sich mit der Charakterisierung von Tasks, der Online-Vorhersage von Lastwerten und der Verwendung der Vorhersageergebnisse zur Steuerung der Entlastung von Tasks. Anstelle des fehlenden Vorwissens vor der Ausführung der Applikation haben wir nun Vorhersagewissen über die Last zur Laufzeit. Dadurch kann unser Ansatz Informationen für die Task-Migration abschätzen, z.B. die Anzahl der gleichzeitig ausgelagerten Tasks und potentielle Opfer.\\

% \clearpage

% Ausblick
% Zur Bewertung der vorgeschlagenen Lösung werden sowohl Simulatoren als auch Experimente eingesetzt. Wir zeigen zwei Referenzimplementierungen mit Task-basierten parallelen Programmiermodellen. Für die Anwendungsfälle verwenden wir einen synthetischen Mikro-Benchmark und eine realistische Applikation. Unsere Ergebnisse bestätigen die Vorteile in Fällen mit hohem Ungleichgewicht, was zu einem Speedup von etwa $1.5\times$ - $3.5\times$ führt. Langfristig eröffnet unser Ansatz ein neues Schema für die gemeinsame Planung von Aufgaben über mehrere Programme hinweg, wenn die internen Ausgleichsprozesse in einer einzelnen Applikation an ihre Grenzen stoßen.