% Context & Challenge & Traditional Method
%High performance computing (HPC) is a key technology in science by using supercomputers to solve complex computation problems. In supercomputers, the architecture is geared towards parallel computing which makes advanced computations possible, and computation problems are represented as task parallel applications. Supercomputers today refer to parallel computer clusters, where load imbalance is often a challenge to task parallel applications running on clusters. Regarding imbalance context, this thesis focuses on dynamic load balancing caused by system performance slowdown on a given task distribution, making pre-partitioning or static approaches difficult to balance the load at runtime.

% High performance computing (HPC) is a key technology in science and research to solve complex computational problems. HPC uses parallel computing, which refers to parallel compute clusters to perform advanced computation. Thus, the computational problems have to be represented as task parallel applications on these clusters. Load balancing is often a challenge for task parallel applications. This thesis focuses on dynamic load balancing caused by performance slowdown, making pre-partitioning or static approaches difficult to balance the load before runtime.

High performance computing (HPC) plays a key role in scientific and research, solving intricate computational problems. HPC relies on parallel computing, involving the use of parallel compute clusters for advanced computations. Thus, computational problems have to be represented as task parallel applications on these clusters. However, load balancing is often a challenge for task parallel applications, particularly when dealing with imbalances caused by performance slowdown. This dynamic nature makes traditional approaches like pre-partitioning or static load balancing less effective.\\

% Current Directions, Constraints, and State-of-the-art
% At runtime, work stealing is a useful approach to deal with performance slowdown, in which tasks are stolen if a process is idle. Tasks and data must be migrated among machines to balance the load, but communication overhead in parallel computer clusters can delay stealing operations. An improvement is reactive load balancing, where people propose offloading tasks earlier from a slow process to a fast one instead of stealing. However, this thesis shows that the reactive approach can also be limited when task offloading is driven insufficiently and incorrectly due to speculative decisions. Furthermore, lack of load information is a reason we cannot adapt for a better task offloading decision, e.g., how many tasks should be migrated at once, which process is a potential victim.

% A useful approach to deal with performance slowdown at runtime is work stealing, in which tasks are stolen from another one if a process is idle. Tasks and data must be migrated among nodes to balance the load, but communication overhead in parallel compute clusters can delay stealing operations. An improvement is reactive load balancing, which proposes offloading tasks from a slow process to a fast one earlier instead of stealing. However, the reactive approach can also be limited when task offloading is driven insufficiently and incorrectly due to speculative decisions. Furthermore, lack of load information is a reason which prevents better task offloading decisions.

A useful approach to deal with performance slowdown at runtime is ``work stealing'', where an idle process can take tasks from others. It involves the migration of tasks and data among nodes, but communication overhead in parallel compute clusters can delay stealing operations. An improvement is ``reactive load balancing'', which proposes task offloading from a slow process to a fast one earlier than stealing. This reactive approach has limitations when task offloading decisions are driven by speculation. Furthermore, lack of load information is also a reason, impeding these decisions.\\

% The thesis's solution
% First, this thesis contributes a performance model to analyze the limit of reactive load balancing as well as work stealing. Second, we motivate a new proactive approach to enhance performance further. The main concept revolves around the real-time acquisition of load information, which facilitates a more proactive load balancing strategy. In detail, we exploit the execution scheme of task-based programming models, where one thread is dedicated to performing task characterization, online load prediction, and proactive task offloading based on prediction output. Therefore, we have load prediction knowledge instead of missing prior knowledge during execution. This enables us to make more accurate estimations regarding task numbers and potential processes for migration. Within this approach, we put forth two methods for guiding task offloading, along with an extension that allows co-scheduling tasks across multiple applications.

% This thesis contributes a performance model to analyze the limit of reactive load balancing. We motivate a new proactive approach to enhance performance even further. The main concept revolves around the real-time acquisition of load information, which facilitates a more proactive load balancing strategy. In detail, we exploit the execution scheme of task-based programming models, where one thread in a process is dedicated to performing task characterization, online load prediction, and proactive task offloading based on prediction output. Therefore, we obtain load prediction knowledge instead of missing prior knowledge during execution. This enables us to make more accurate estimations regarding task numbers and potential processes for migration. Within our approach, we propose two methods for guiding task offloading, along with an extension that allows co-scheduling tasks across multiple applications.

Our work contributes a performance model to analyze the limits of reactive load balancing. We propose a new proactive approach to enhance performance even further. The main concept revolves around real-time load information acquisition, enabling a more proactive load balancing strategy. In detail, we leverage the execution scheme of task-based programming models, where one thread within a process is dedicated to task characterization, online load prediction, and proactive task offloading based on prediction outputs. We obtain load prediction knowledge instead of missing prior knowledge during execution. We can make more accurate estimations regarding the number of tasks and potential processes for task migration. Within our approach, we introduce two balancing methods: feedback task offloading and machine learning-based task offloading. Besides that, we propose an extension that facilitates co-scheduling tasks across multiple applications.\\

% Outlook
% Both simulators and experiments are introduced to evaluate the proposed approach. The test cases include synthetic microbenchmarks and a realistic application of adaptive mesh refinement. Our results confirm benefits in high imbalance cases, gaining in speedup around $3.5\times$ compared to randomized work stealing and $1.7\times$ to reactive load balancing. For a broader vision, our approach opens a new scheme for co-scheduling tasks across multiple applications, aimed at enhancing not only the performance and resource utilization of a single application but multiple ones.

To evaluate the efficacy of our approach, we employ both simulations and experimental tests. The test cases include synthetic microbenchmarks and a realistic application involving adaptive mesh refinement. Our results confirm benefits in high imbalance scenarios, showcasing a speedup of approximately $3.5\times$ when compared to randomized work stealing, and $1.7\times$ when compared to reactive load balancing. In a broader vision, our approach opens a new scheme for co-scheduling tasks across multiple applications, enhancing not only the performance and resource utilization of a single application but multiple ones.

